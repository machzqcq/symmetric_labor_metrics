{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is converting already download data into parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.7/site-packages (1.16.1)\n",
      "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.7/site-packages (0.25.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/site-packages (from pandas==0.25.3) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/site-packages (from pandas==0.25.3) (1.16.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==0.25.3) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas==0.25.3) (1.13.0)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/site-packages (0.15.1)\n",
      "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.7/site-packages (from pyarrow) (1.13.0)\n",
      "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/site-packages (from pyarrow) (1.16.1)\n",
      "Requirement already satisfied: fastparquet in /usr/local/lib/python3.7/site-packages (0.3.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from fastparquet) (1.13.0)\n",
      "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/site-packages (from fastparquet) (0.25.3)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/site-packages (from fastparquet) (1.16.1)\n",
      "Requirement already satisfied: numba>=0.28 in /usr/local/lib/python3.7/site-packages (from fastparquet) (0.46.0)\n",
      "Requirement already satisfied: thrift>=0.11.0 in /usr/local/lib/python3.7/site-packages (from fastparquet) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/site-packages (from pandas>=0.19->fastparquet) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas>=0.19->fastparquet) (2019.3)\n",
      "Requirement already satisfied: llvmlite>=0.30.0dev0 in /usr/local/lib/python3.7/site-packages (from numba>=0.28->fastparquet) (0.30.0)\n",
      "Collecting xlrd\n",
      "  Using cached https://files.pythonhosted.org/packages/b0/16/63576a1a001752e34bf8ea62e367997530dc553b689356b9879339cf45a4/xlrd-1.2.0-py2.py3-none-any.whl\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-1.2.0\n"
     ]
    }
   ],
   "source": [
    "# pyarrow and fastparquet are engines required for pandas to convert to parquet\n",
    "# 1.16.1 because of https://github.com/scikit-learn-contrib/hdbscan/issues/272. \n",
    "# First install numpy and then pandas==0.25.3, because pandas uses numpy to compile and build\n",
    "! pip install numpy==1.16.1\n",
    "! pip install pandas==0.25.3\n",
    "! pip install pyarrow\n",
    "! pip install fastparquet\n",
    "! pip install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "FOLDER_NAME = \"LCAProgramsH1BH1B1E3\"\n",
    "# YEAR_MONTH = datetime.today().strftime(\"%Y-%m\")\n",
    "YEAR_MONTH = \"2019-10\"\n",
    "# Assuming all data is inside us-visa-data folder\n",
    "DOWNLOAD_DIR = os.getenv('DOWNLOAD_DIR', '../us-visa-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all data to parquet for efficient access and analytics\n",
    "- Define a function, that takes file, folder name, year_month\n",
    "- Use the function return_data_types to enforce data types for all columns, because saving to parquet with mixed data types, non-homonenous values etc. is a pain to fix at execution time. Just narrow down all data types (big manual work) and life gets easier \n",
    "- Saves the parquet file to the same location in which data file exists\n",
    "- As soon as you save parquet file, read it back and ensure that there is no data loss i.e. original and parquet contain same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "def return_data_types(layout_file_name, folder_name, year_month):\n",
    "    \n",
    "    # Get download directory if DOWNLOAD_DIR is set, otherwise current directory. \n",
    "    # Directory is relative to where this notebook exists\n",
    "    DOWNLOAD_DIR = os.getenv('DOWNLOAD_DIR', \"../us-visa-data\")\n",
    "    \n",
    "    df_data_types = pd.read_excel(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" + year_month + \"/data_types.xlsx\", sheet_name= folder_name, header=None)\n",
    "    # Get the row where first column matches the input string in this case file layout and coerce to a list\n",
    "    my_keys = df_data_types.loc[df_data_types.iloc[:,0]==layout_file_name].values[0].tolist()\n",
    "    print(\"Keys for {0}: {1}\".format(layout_file_name, my_keys))\n",
    "    # Remove the first element, as it is the filename\n",
    "    del my_keys[-1]\n",
    "    if(len(my_keys) != 0):\n",
    "        # +1 because the dtypes are actually in the next row\n",
    "        my_values = df_data_types.loc[df_data_types.loc[df_data_types.iloc[:,0]==layout_file_name].index[0]+1].values.tolist()\n",
    "        # Remove the first element, as it just a placeholder\n",
    "        del my_values[-1]\n",
    "        if(len(my_keys)==len(my_values)):\n",
    "            print(\"Data types: {0}\".format(dict(zip(my_keys, my_values))))\n",
    "            return dict(zip(my_keys, my_values))\n",
    "        else:\n",
    "            print(\"Length of {keys} is NOT equal to length of {vaules}\".format(keys=my_keys,values=my_values))\n",
    "    else:\n",
    "        print(\"Data types for {0} not found in data_types.xlsx\".format(layout_file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import pandas as pd\n",
    "def convert_file_to_parquet_delimited(file, layout_file_name, folder_name, year_month):\n",
    "    file = file.split('/')[-1]\n",
    "    actual_filename, actual_file_extension = os.path.splitext(file)\n",
    "\n",
    "    # Assuming all data is inside us-visa-data folder\n",
    "    DOWNLOAD_DIR = os.getenv('DOWNLOAD_DIR', '../us-visa-data')\n",
    "\n",
    "    pathlib.Path(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" + year_month + \"/downloads/parquet/\").mkdir(\n",
    "    parents=True, exist_ok=True)\n",
    "    \n",
    "    # Convert only the actual data files, no need to convert .doc, .pdf\n",
    "    if(actual_file_extension == '.xlsx'):\n",
    "        if(os.path.exists(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" + year_month + \"/downloads/parquet/\" + actual_filename + \".snappy.parquet\") or os.path.exists(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" + year_month + \"/downloads/parquet/\" + actual_filename + \".gzip.parquet\")):\n",
    "            print(\"{0} already exists\".format(actual_filename + \".snappy.parquet\"))\n",
    "        else:\n",
    "            print(\"Reading excel file to dataframe....{file}\".format(file=actual_filename + actual_file_extension))\n",
    "            df = pd.read_excel(os.path.join(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" + year_month \n",
    "                                            + \"/downloads/\", actual_filename + actual_file_extension), \n",
    "                               dtype=return_data_types(layout_file_name, folder_name, year_month))\n",
    "            print(\"Converting {orig_file} to parquet\".format(orig_file=actual_filename + actual_file_extension))\n",
    "            # Mixed data types don't save to parquet and errors. for e.g. BUSINESS_NAME had integer value and the below fails\n",
    "            df.to_parquet(os.path.join(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" \n",
    "                                       + year_month + \"/downloads/parquet/\", actual_filename \n",
    "                                       + \".snappy.parquet\"), compression='snappy', engine=\"pyarrow\",index=False) # index=False so that row indexes are not saved\n",
    "           # Data quality check\n",
    "            df_parquet = pd.read_parquet(os.path.join(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" + year_month + \"/downloads/parquet/\", actual_filename + \".snappy.parquet\"))\n",
    "            if(df.equals(df_parquet)):\n",
    "                print(\"{orig_file} has same data and datatypes as that of converted {parquet_file}\".format(orig_file=actual_filename+\".xlsx\", parquet_file=actual_filename+\".snappy.parquet\"))\n",
    "            else:\n",
    "                print(\"{orig_file} does NOT have same data or datatypes as that of converted {parquet_file}\".format(orig_file=actual_filename+\".xlsx\", parquet_file=actual_filename+\".snappy.parquet\"))\n",
    "                print(df.info())\n",
    "                print(df_parquet.info())\n",
    "            # Delete dataframe and release memory\n",
    "            if not df.empty:\n",
    "                del df \n",
    "            if not df_parquet.empty:\n",
    "                del df_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of files to download: ['H-1B_Disclosure_Data_FY2019.xlsx', 'H-1B_Disclosure_Data_FY2018_EOY.xlsx', 'H-1B_Disclosure_Data_FY17.xlsx', 'H-1B_Disclosure_Data_FY16.xlsx', 'H-1B_Disclosure_Data_FY15_Q4.xlsx', 'H-1B_FY14_Q4.xlsx', 'LCA_FY2013.xlsx', 'LCA_FY2012_Q4.xlsx', 'H-1B_iCert_LCA_FY2011_Q4.xlsx', 'H-1B_FY2010.xlsx', 'Icert_ LCA_ FY2009.xlsx', 'H-1B_Case_Data_FY2009.xlsx', 'H-1B_Case_Data_FY2008.xlsx']\n",
      "Corresponding layout files: ['H-1B_FY19_Record_Layout.pdf', 'H-1B_FY18_Record_Layout.pdf', 'H-1B_FY17_Record_Layout.pdf', 'H-1B_FY16_Record_Layout.pdf', 'H-1B_FY15_Record_Layout.docx', 'H1B_FY14_Record_Layout.doc', 'LCA_Record_Layout_FY13.doc', 'LCA_Record_Layout_FY12.doc', 'H-1B_Record_Layout_FY11_Q4.doc', 'H-1B_Record_Layout_FY10.doc', 'H1B_Layout_FY09.doc', 'H-1B Efile Record Layout FY09.rtf', 'H-1B_Record_Layout_FY08.doc']\n",
      "Processing file: H-1B_Disclosure_Data_FY2019.xlsx\n",
      "H-1B_FY19_Record_Layout.pdf\n",
      "Reading excel file to dataframe....H-1B_Disclosure_Data_FY2019.xlsx\n",
      "Keys for H-1B_FY19_Record_Layout.pdf: ['H-1B_FY19_Record_Layout.pdf', 'CASE_NUMBER', 'CASE_STATUS', 'CASE_SUBMITTED', 'DECISION_DATE', 'ORIGINAL_CERT_DATE', 'VISA_CLASS', 'EMPLOYMENT_START_DATE', 'EMPLOYMENT_END_DATE', 'EMPLOYER_NAME', 'EMPLOYER_BUSINESS_DBA', 'EMPLOYER_ADDRESS', 'EMPLOYER_CITY', 'EMPLOYER_STATE', 'EMPLOYER_POSTAL_CODE', 'EMPLOYER_COUNTRY', 'EMPLOYER_PROVINCE', 'EMPLOYER_PHONE', 'EMPLOYER_PHONE_EXT', 'SECONDARY_ENTITY', 'SECONDARY_ENTITY_BUSINESS_NAME', 'AGENT_REPRESENTING_EMPLOYER', 'AGENT_ATTORNEY_NAME', 'AGENT_ATTORNEY_CITY', 'AGENT_ATTORNEY_STATE', 'JOB_TITLE', 'SOC_CODE', 'SOC_NAME', 'NAICS_CODE', 'TOTAL_WORKERS', 'NEW_EMPLOYMENT', 'CONTINUED_EMPLOYMENT', 'CHANGE_PREVIOUS_EMPLOYMENT', 'NEW_CONCURRENT_EMPLOYMENT', 'CHANGE_EMPLOYER', 'AMENDED_PETITION', 'FULL_TIME_POSITION', 'PREVAILING_WAGE', 'PW_UNIT_OF_PAY', 'PW_WAGE_LEVEL', 'PW_SOURCE', 'PW_SOURCE_OTHER', 'WAGE_RATE_OF_PAY_FROM', 'WAGE_RATE_OF_PAY_TO', 'WAGE_UNIT_OF_PAY', 'H-1B_DEPENDENT', 'WORKSITE_CITY', 'WORKSITE_COUNTY', 'WORKSITE_STATE', 'WORKSITE_POSTAL_CODE', 'WILLFUL_VIOLATOR', 'SUPPORT_H1B', 'STATUTORY_BASIS', 'MASTERS_EXEMPTION', 'APPX_A_NO_OF_EXEMPT_WORKER_1', 'APPX_A_NAME_OF_INSTITUTION_1', 'APPX_A_FIELD_OF_STUDY_1', 'APPX_A_DATE_OF_DEGREE_1', 'APPX_A_NO_OF_EXEMPT_WORKER_2', 'APPX_A_NAME_OF_INSTITUTION_2', 'APPX_A_FIELD_OF_STUDY_2', 'APPX_A_DATE_OF_DEGREE_2', 'APPX_A_NO_OF_EXEMPT_WORKER_3', 'APPX_A_NAME_OF_INSTITUTION_3', 'APPX_A_FIELD_OF_STUDY_3', 'APPX_A_DATE_OF_DEGREE_3', 'APPX_A_NO_OF_EXEMPT_WORKER_4', 'APPX_A_NAME_OF_INSTITUTION_4', 'APPX_A_FIELD_OF_STUDY_4', 'APPX_A_DATE_OF_DEGREE_4', 'APPX_A_NO_OF_EXEMPT_WORKER_5', 'APPX_A_NAME_OF_INSTITUTION_5', 'APPX_A_FIELD_OF_STUDY_5', 'APPX_A_DATE_OF_DEGREE_5']\n",
      "Data types: {'H-1B_FY19_Record_Layout.pdf': 'dtypes', 'CASE_NUMBER': 'str', 'CASE_STATUS': 'str', 'CASE_SUBMITTED': 'datetime64', 'DECISION_DATE': 'datetime64', 'ORIGINAL_CERT_DATE': 'datetime64', 'VISA_CLASS': 'str', 'EMPLOYMENT_START_DATE': 'str', 'EMPLOYMENT_END_DATE': 'str', 'EMPLOYER_NAME': 'str', 'EMPLOYER_BUSINESS_DBA': 'str', 'EMPLOYER_ADDRESS': 'str', 'EMPLOYER_CITY': 'str', 'EMPLOYER_STATE': 'str', 'EMPLOYER_POSTAL_CODE': 'str', 'EMPLOYER_COUNTRY': 'str', 'EMPLOYER_PROVINCE': 'str', 'EMPLOYER_PHONE': 'str', 'EMPLOYER_PHONE_EXT': 'str', 'SECONDARY_ENTITY': 'str', 'SECONDARY_ENTITY_BUSINESS_NAME': 'str', 'AGENT_REPRESENTING_EMPLOYER': 'str', 'AGENT_ATTORNEY_NAME': 'str', 'AGENT_ATTORNEY_CITY': 'str', 'AGENT_ATTORNEY_STATE': 'str', 'JOB_TITLE': 'str', 'SOC_CODE': 'str', 'SOC_NAME': 'str', 'NAICS_CODE': 'str', 'TOTAL_WORKERS': 'str', 'NEW_EMPLOYMENT': 'str', 'CONTINUED_EMPLOYMENT': 'str', 'CHANGE_PREVIOUS_EMPLOYMENT': 'str', 'NEW_CONCURRENT_EMPLOYMENT': 'str', 'CHANGE_EMPLOYER': 'str', 'AMENDED_PETITION': 'str', 'FULL_TIME_POSITION': 'str', 'PREVAILING_WAGE': 'str', 'PW_UNIT_OF_PAY': 'str', 'PW_WAGE_LEVEL': 'str', 'PW_SOURCE': 'str', 'PW_SOURCE_OTHER': 'str', 'WAGE_RATE_OF_PAY_FROM': 'str', 'WAGE_RATE_OF_PAY_TO': 'str', 'WAGE_UNIT_OF_PAY': 'str', 'H-1B_DEPENDENT': 'str', 'WORKSITE_CITY': 'str', 'WORKSITE_COUNTY': 'str', 'WORKSITE_STATE': 'str', 'WORKSITE_POSTAL_CODE': 'str', 'WILLFUL_VIOLATOR': 'str', 'SUPPORT_H1B': 'str', 'STATUTORY_BASIS': 'str', 'MASTERS_EXEMPTION': 'str', 'APPX_A_NO_OF_EXEMPT_WORKER_1': 'str', 'APPX_A_NAME_OF_INSTITUTION_1': 'str', 'APPX_A_FIELD_OF_STUDY_1': 'str', 'APPX_A_DATE_OF_DEGREE_1': 'str', 'APPX_A_NO_OF_EXEMPT_WORKER_2': 'str', 'APPX_A_NAME_OF_INSTITUTION_2': 'str', 'APPX_A_FIELD_OF_STUDY_2': 'str', 'APPX_A_DATE_OF_DEGREE_2': 'str', 'APPX_A_NO_OF_EXEMPT_WORKER_3': 'str', 'APPX_A_NAME_OF_INSTITUTION_3': 'str', 'APPX_A_FIELD_OF_STUDY_3': 'str', 'APPX_A_DATE_OF_DEGREE_3': 'str', 'APPX_A_NO_OF_EXEMPT_WORKER_4': 'str', 'APPX_A_NAME_OF_INSTITUTION_4': 'str', 'APPX_A_FIELD_OF_STUDY_4': 'str', 'APPX_A_DATE_OF_DEGREE_4': 'str', 'APPX_A_NO_OF_EXEMPT_WORKER_5': 'str', 'APPX_A_NAME_OF_INSTITUTION_5': 'str', 'APPX_A_FIELD_OF_STUDY_5': 'str'}\n",
      "Converting H-1B_Disclosure_Data_FY2019.xlsx to parquet\n",
      "H-1B_Disclosure_Data_FY2019.xlsx has same data and datatypes as that of converted H-1B_Disclosure_Data_FY2019.snappy.parquet\n",
      "Processing file: H-1B_Disclosure_Data_FY2018_EOY.xlsx\n",
      "H-1B_FY18_Record_Layout.pdf\n",
      "H-1B_Disclosure_Data_FY2018_EOY.snappy.parquet already exists\n",
      "Processing file: H-1B_Disclosure_Data_FY17.xlsx\n",
      "H-1B_FY17_Record_Layout.pdf\n",
      "H-1B_Disclosure_Data_FY17.snappy.parquet already exists\n",
      "Processing file: H-1B_Disclosure_Data_FY16.xlsx\n",
      "H-1B_FY16_Record_Layout.pdf\n",
      "H-1B_Disclosure_Data_FY16.snappy.parquet already exists\n",
      "Processing file: H-1B_Disclosure_Data_FY15_Q4.xlsx\n",
      "H-1B_FY15_Record_Layout.docx\n",
      "H-1B_Disclosure_Data_FY15_Q4.snappy.parquet already exists\n",
      "Processing file: H-1B_FY14_Q4.xlsx\n",
      "H1B_FY14_Record_Layout.doc\n",
      "H-1B_FY14_Q4.snappy.parquet already exists\n",
      "Processing file: LCA_FY2013.xlsx\n",
      "LCA_Record_Layout_FY13.doc\n",
      "LCA_FY2013.snappy.parquet already exists\n",
      "Processing file: LCA_FY2012_Q4.xlsx\n",
      "LCA_Record_Layout_FY12.doc\n",
      "LCA_FY2012_Q4.snappy.parquet already exists\n",
      "Processing file: H-1B_iCert_LCA_FY2011_Q4.xlsx\n",
      "H-1B_Record_Layout_FY11_Q4.doc\n",
      "H-1B_iCert_LCA_FY2011_Q4.snappy.parquet already exists\n",
      "Processing file: H-1B_FY2010.xlsx\n",
      "H-1B_Record_Layout_FY10.doc\n",
      "H-1B_FY2010.snappy.parquet already exists\n",
      "Processing file: Icert_ LCA_ FY2009.xlsx\n",
      "H1B_Layout_FY09.doc\n",
      "Icert_ LCA_ FY2009.snappy.parquet already exists\n",
      "Processing file: H-1B_Case_Data_FY2009.xlsx\n",
      "H-1B Efile Record Layout FY09.rtf\n",
      "H-1B_Case_Data_FY2009.snappy.parquet already exists\n",
      "Processing file: H-1B_Case_Data_FY2008.xlsx\n",
      "H-1B_Record_Layout_FY08.doc\n",
      "H-1B_Case_Data_FY2008.snappy.parquet already exists\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "regex = re.compile(\n",
    "        r'^(?:http|ftp)s?://' # http:// or https://\n",
    "        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n",
    "        r'localhost|' #localhost...\n",
    "        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n",
    "        r'(?::\\d+)?' # optional port\n",
    "        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "\n",
    "# Read already downloaded table map\n",
    "table_map = pd.read_csv(DOWNLOAD_DIR + \"/\" + FOLDER_NAME + \"/\" + YEAR_MONTH + \"/\" + FOLDER_NAME + \"_map.csv\")\n",
    "files = table_map['Actual Disclosure File Name'].tolist()\n",
    "print(\"List of files to download: {0}\".format(files))\n",
    "print(\"Corresponding layout files: {0}\".format(table_map['Actual File Structure'].tolist()))\n",
    "\n",
    "# Use the below two lines of code for testing a single file\n",
    "# layout_file_name = table_map[table_map['Actual Disclosure File Name'] == 'PERM_Disclosure_Data_FY2019.xlsx']['Actual File Structure']\n",
    "# convert_file_to_parquet_delimited(\"H-1B_Case_Data_FY2009.xlsx\", \"H-1B Efile Record Layout FY09.rtf\", FOLDER_NAME, YEAR_MONTH)\n",
    "\n",
    "for file in files:\n",
    "    print(\"Processing file: {0}\".format(file))\n",
    "    layout_file_name = table_map[table_map['Actual Disclosure File Name'] == file]['Actual File Structure'].values[0]\n",
    "    print(layout_file_name)\n",
    "    convert_file_to_parquet_delimited(file, layout_file_name, FOLDER_NAME, YEAR_MONTH)\n",
    "    time.sleep(5) # Sleep to give rest to the CPU ;) jk, this line is remnant from other function\n",
    "\n",
    "# clean up and remove from memory\n",
    "del table_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
