{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is converting already download data into parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/site-packages (1.16.1)\n",
      "Requirement already satisfied: pandas==0.25.2 in /usr/local/lib/python3.6/site-packages (0.25.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas==0.25.2) (2017.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/site-packages (from pandas==0.25.2) (1.16.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/site-packages (from pandas==0.25.2) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas==0.25.2) (1.11.0)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/site-packages (0.15.1)\n",
      "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/site-packages (from pyarrow) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/site-packages (from pyarrow) (1.16.1)\n",
      "Requirement already satisfied: fastparquet in /usr/local/lib/python3.6/site-packages (0.3.2)\n",
      "Requirement already satisfied: numba>=0.28 in /usr/local/lib/python3.6/site-packages (from fastparquet) (0.46.0)\n",
      "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/site-packages (from fastparquet) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/site-packages (from fastparquet) (1.16.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from fastparquet) (1.11.0)\n",
      "Requirement already satisfied: thrift>=0.11.0 in /usr/local/lib/python3.6/site-packages (from fastparquet) (0.11.0)\n",
      "Requirement already satisfied: llvmlite>=0.30.0dev0 in /usr/local/lib/python3.6/site-packages (from numba>=0.28->fastparquet) (0.30.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/site-packages (from pandas>=0.19->fastparquet) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas>=0.19->fastparquet) (2017.2)\n",
      "Collecting jupyter_nbextensions_configurator\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/a3/d72d5f2dc10c5ccf5a6f4c79f636bf071a5ce462dedd07af2f70384db6cb/jupyter_nbextensions_configurator-0.4.1.tar.gz (479kB)\n",
      "\u001b[K     |████████████████████████████████| 481kB 1.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter_contrib_core>=0.3.3\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/8f/04a752a8b66a66e7092c035e5d87d2502ac7ec07f9fb6059059b6c0dc272/jupyter_contrib_core-0.3.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jupyter_core in /usr/local/lib/python3.6/site-packages (from jupyter_nbextensions_configurator) (4.5.0)\n",
      "Requirement already satisfied: notebook>=4.0 in /usr/local/lib/python3.6/site-packages (from jupyter_nbextensions_configurator) (6.0.1)\n",
      "Processing /Users/pmacharl/Library/Caches/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030/PyYAML-5.1.2-cp36-cp36m-macosx_10_12_x86_64.whl\n",
      "Requirement already satisfied: tornado in /usr/local/lib/python3.6/site-packages (from jupyter_nbextensions_configurator) (6.0.3)\n",
      "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/site-packages (from jupyter_nbextensions_configurator) (4.3.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from jupyter_contrib_core>=0.3.3->jupyter_nbextensions_configurator) (32.2.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/site-packages (from notebook>=4.0->jupyter_nbextensions_configurator) (0.2.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/site-packages (from notebook>=4.0->jupyter_nbextensions_configurator) (5.6.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/site-packages (from notebook>=4.0->jupyter_nbextensions_configurator) (0.8.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/site-packages (from notebook>=4.0->jupyter_nbextensions_configurator) (2.10.1)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/site-packages (from notebook>=4.0->jupyter_nbextensions_configurator) (4.4.0)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/site-packages (from notebook>=4.0->jupyter_nbextensions_configurator) (5.1.2)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.6/site-packages (from notebook>=4.0->jupyter_nbextensions_configurator) (18.1.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/site-packages (from notebook>=4.0->jupyter_nbextensions_configurator) (0.7.1)\n",
      "Requirement already satisfied: jupyter-client>=5.3.1 in /usr/local/lib/python3.6/site-packages (from notebook>=4.0->jupyter_nbextensions_configurator) (5.3.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/site-packages (from notebook>=4.0->jupyter_nbextensions_configurator) (1.5.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from traitlets->jupyter_nbextensions_configurator) (1.11.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/site-packages (from traitlets->jupyter_nbextensions_configurator) (4.4.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook>=4.0->jupyter_nbextensions_configurator) (1.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook>=4.0->jupyter_nbextensions_configurator) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook>=4.0->jupyter_nbextensions_configurator) (0.6.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook>=4.0->jupyter_nbextensions_configurator) (2.4.2)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook>=4.0->jupyter_nbextensions_configurator) (0.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook>=4.0->jupyter_nbextensions_configurator) (0.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/site-packages (from nbconvert->notebook>=4.0->jupyter_nbextensions_configurator) (3.1.0)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/site-packages (from terminado>=0.8.1->notebook>=4.0->jupyter_nbextensions_configurator) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/site-packages (from jinja2->notebook>=4.0->jupyter_nbextensions_configurator) (1.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/site-packages (from nbformat->notebook>=4.0->jupyter_nbextensions_configurator) (3.0.2)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.6/site-packages (from ipykernel->notebook>=4.0->jupyter_nbextensions_configurator) (7.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from jupyter-client>=5.3.1->notebook>=4.0->jupyter_nbextensions_configurator) (2.6.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.0->jupyter_nbextensions_configurator) (0.5.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.0->jupyter_nbextensions_configurator) (0.15.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.0->jupyter_nbextensions_configurator) (19.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.0->jupyter_nbextensions_configurator) (4.7.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.0->jupyter_nbextensions_configurator) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.0->jupyter_nbextensions_configurator) (0.15.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.0->jupyter_nbextensions_configurator) (2.0.9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /usr/local/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.0->jupyter_nbextensions_configurator) (0.1.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.0->jupyter_nbextensions_configurator) (0.7.5)\n",
      "Requirement already satisfied: parso>=0.5.0 in /usr/local/lib/python3.6/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->notebook>=4.0->jupyter_nbextensions_configurator) (0.5.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook>=4.0->jupyter_nbextensions_configurator) (0.1.7)\n",
      "Building wheels for collected packages: jupyter-nbextensions-configurator\n",
      "  Building wheel for jupyter-nbextensions-configurator (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jupyter-nbextensions-configurator: filename=jupyter_nbextensions_configurator-0.4.1-py2.py3-none-any.whl size=466145 sha256=89bbfb642cd6d17a5b912c0900ad8725cdca74f7ed3fb3bebcd04b6bde8d85b7\n",
      "  Stored in directory: /Users/pmacharl/Library/Caches/pip/wheels/15/df/fe/2a74fe34709e7fdc5ae153a768675d9fda93cc7d5133ed1fb0\n",
      "Successfully built jupyter-nbextensions-configurator\n",
      "Installing collected packages: jupyter-contrib-core, pyyaml, jupyter-nbextensions-configurator\n",
      "Successfully installed jupyter-contrib-core-0.3.3 jupyter-nbextensions-configurator-0.4.1 pyyaml-5.1.2\n"
     ]
    }
   ],
   "source": [
    "# pyarrow and fastparquet are engines required for pandas to convert to parquet\n",
    "# 1.16.1 because of https://github.com/scikit-learn-contrib/hdbscan/issues/272. \n",
    "# First install numpy and then pandas==0.25.2, because pandas uses numpy to compile and build\n",
    "! pip install numpy==1.16.1\n",
    "! pip install pandas==0.25.2\n",
    "! pip install pyarrow\n",
    "! pip install fastparquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "FOLDER_NAME = \"LCAProgramsH1BH1B1E3\"\n",
    "# YEAR_MONTH = datetime.today().strftime(\"%Y-%m\")\n",
    "YEAR_MONTH = \"2019-10\"\n",
    "# Assuming all data is inside us-visa-data folder\n",
    "DOWNLOAD_DIR = os.getenv('DOWNLOAD_DIR', '../us-visa-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all data to parquet for efficient access and analytics\n",
    "- Define a function, that takes file, folder name, year_month\n",
    "- Use the function return_data_types to enforce data types for all columns, because saving to parquet with mixed data types, non-homonenous values etc. is a pain to fix at execution time. Just narrow down all data types (big manual work) and life gets easier \n",
    "- Saves the parquet file to the same location in which data file exists\n",
    "- As soon as you save parquet file, read it back and ensure that there is no data loss i.e. original and parquet contain same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are only two layouts , hence easier to define it here itself\n",
    "import pandas as pd\n",
    "efile_keys = ['Submitted_Date','Case_No','Program (2007 Only)','Name','Address','Address2','City','State','Postal_Code','Nbr_Immigrants','Begin_Date','End_Date','Job_Title','Dol_Decision_Date','Certified_Begin_Date','Certified_End_Date','Job_Code','Approval_Status','Wage_Rate_1','Rate_Per_1','Max_Rate_1','Part_Time_1','City_1','State_1','Prevailing_Wage_1','Wage_Source_1','Yr_Source_Pub_1','Other_Wage_Source_1','Wage_Rate_2','Rate_Per_2','Max_Rate_2','Part_Time_2','City_2','State_2','Prevailing_Wage_2','Wage_Source_2','Yr_Source_Pub_2','Other_Wage_Source_2','Withdrawn']\n",
    "efile_values = ['str' for i in efile_keys]\n",
    "efile_data_types = dict(zip(keys,values))\n",
    "fax_keys = ['C_num','CertCode','ReturnFax','EmpName','EmpCity','EmpAddy1','EmpAddy2','EmpState','EmpZip','WageRateFrom','WageRateTo','RatePer','PartTime','BeginDate','EndDate','JobCode','NumImmigrants','JobTitle','WorkCity_1','WorkState_1','PrevWage_1','PrevWagePer_1','WageSource_1','WorkYear1','OtherWageSource1','WorkCity2','WorkState2','PrevWage2','PrevWagePer_2','WageSource_2','WorkYear_2','OtherWageSource2','CertStart','CertEnd','Det_Date','ProcessDate']\n",
    "fax_values = ['str' for i in fax_keys]\n",
    "fax_data_types = dict(zip(keys,values))\n",
    "d = {'efile': efile_data_types, 'fax': fax_data_types}\n",
    "df_data_types = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "def convert_file_to_parquet_delimited(file, layout_file_name, folder_name, year_month, send_type):\n",
    "    file = file.split('/')[-1]\n",
    "    actual_filename, actual_file_extension = os.path.splitext(file)\n",
    "\n",
    "    # Assuming all data is inside us-visa-data folder\n",
    "    DOWNLOAD_DIR = os.getenv('DOWNLOAD_DIR', '../us-visa-data')\n",
    "\n",
    "    pathlib.Path(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" + year_month + \"/downloads/parquet/\").mkdir(\n",
    "    parents=True, exist_ok=True)\n",
    "    \n",
    "    # Convert only the actual data files all files prior to 2007 were in .txt or mdb\n",
    "    if(actual_file_extension == '.txt'):\n",
    "        if(os.path.exists(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" + year_month + \"/downloads/parquet/\" + actual_filename + \".snappy.parquet\") or os.path.exists(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" + year_month + \"/downloads/parquet/\" + actual_filename + \".gzip.parquet\")):\n",
    "            print(\"{0} already exists\".format(actual_filename + \".snappy.parquet\"))\n",
    "        else:\n",
    "            print(\"Reading text file to dataframe....{file}\".format(file=actual_filename + actual_file_extension))\n",
    "            df = pd.read_csv(os.path.join(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" + year_month \n",
    "                                            + \"/downloads/\", actual_filename + actual_file_extension), \n",
    "                               dtype=dict(df_data_types[send_type]), encoding = \"iso-8859-1\", low_memory=False, delimiter=\",\")\n",
    "            print(\"Converting {orig_file} to parquet\".format(orig_file=actual_filename + actual_file_extension))\n",
    "            # Mixed data types don't save to parquet and errors. for e.g. BUSINESS_NAME had integer value and the below fails\n",
    "            df.to_parquet(os.path.join(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" \n",
    "                                       + year_month + \"/downloads/parquet/\", actual_filename \n",
    "                                       + \".snappy.parquet\"), compression='snappy', engine=\"pyarrow\",index=False) # index=False so that row indexes are not saved\n",
    "           # Data quality check\n",
    "            df_parquet = pd.read_parquet(os.path.join(DOWNLOAD_DIR + \"/\" + folder_name + \"/\" + year_month + \"/downloads/parquet/\", actual_filename + \".snappy.parquet\"))\n",
    "            if(df.equals(df_parquet)):\n",
    "                print(\"{orig_file} has same data and datatypes as that of converted {parquet_file}\".format(orig_file=actual_filename+\".xlsx\", parquet_file=actual_filename+\".snappy.parquet\"))\n",
    "            else:\n",
    "                print(\"{orig_file} does NOT have same data or datatypes as that of converted {parquet_file}\".format(orig_file=actual_filename+\".xlsx\", parquet_file=actual_filename+\".snappy.parquet\"))\n",
    "                print(df.info())\n",
    "                print(df_parquet.info())\n",
    "            # Delete dataframe and release memory\n",
    "            if not df.empty:\n",
    "                del df \n",
    "            if not df_parquet.empty:\n",
    "                del df_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of files to download: ['EFILE_FY2007.txt', 'H1B_efile_FY06.txt', 'H1B_efile_FY05.txt', 'H1B_efile_FY04.txt', 'H1B_efile_FY03.txt', 'H1B_efile_FY02.txt', 'H1B_Fax_FY2006_External_Web.txt', 'H1B_Fax_FY2005_Download.txt', 'H1B_fax_FY04.txt', 'H1b_external_fax_FY04_Web.txt', 'H1B_Fax_FY2003_Download.txt', 'H1B_FAX_FY2002_Download.txt', 'H1B_Fax_FY2001_Download.txt']\n",
      "Corresponding layout files: ['H-1B_Efile_Record_Layout_FY01-07.xlsx', 'H-1B_Efile_Record_Layout_FY01-07.xlsx', 'H-1B_Efile_Record_Layout_FY01-07.xlsx', 'H-1B_Efile_Record_Layout_FY01-07.xlsx', 'H-1B_Efile_Record_Layout_FY01-07.xlsx', 'H-1B_Efile_Record_Layout_FY01-07.xlsx', 'H-1B_Fax_Record_Layout_FY01-07.xlsx', 'H-1B_Fax_Record_Layout_FY01-07.xlsx', 'H-1B_Fax_Record_Layout_FY01-07.xlsx', 'H-1B_Fax_Record_Layout_FY01-07.xlsx', 'H-1B_Fax_Record_Layout_FY01-07.xlsx', 'H-1B_Fax_Record_Layout_FY01-07.xlsx', 'H-1B_Fax_Record_Layout_FY01-07.xlsx']\n",
      "Processing file: EFILE_FY2007.txt\n",
      "H-1B_Efile_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....EFILE_FY2007.txt\n",
      "Converting EFILE_FY2007.txt to parquet\n",
      "EFILE_FY2007.xlsx has same data and datatypes as that of converted EFILE_FY2007.snappy.parquet\n",
      "Processing file: H1B_efile_FY06.txt\n",
      "H-1B_Efile_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....H1B_efile_FY06.txt\n",
      "Converting H1B_efile_FY06.txt to parquet\n",
      "H1B_efile_FY06.xlsx has same data and datatypes as that of converted H1B_efile_FY06.snappy.parquet\n",
      "Processing file: H1B_efile_FY05.txt\n",
      "H-1B_Efile_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....H1B_efile_FY05.txt\n",
      "Converting H1B_efile_FY05.txt to parquet\n",
      "H1B_efile_FY05.xlsx has same data and datatypes as that of converted H1B_efile_FY05.snappy.parquet\n",
      "Processing file: H1B_efile_FY04.txt\n",
      "H-1B_Efile_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....H1B_efile_FY04.txt\n",
      "Converting H1B_efile_FY04.txt to parquet\n",
      "H1B_efile_FY04.xlsx has same data and datatypes as that of converted H1B_efile_FY04.snappy.parquet\n",
      "Processing file: H1B_efile_FY03.txt\n",
      "H-1B_Efile_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....H1B_efile_FY03.txt\n",
      "Converting H1B_efile_FY03.txt to parquet\n",
      "H1B_efile_FY03.xlsx has same data and datatypes as that of converted H1B_efile_FY03.snappy.parquet\n",
      "Processing file: H1B_efile_FY02.txt\n",
      "H-1B_Efile_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....H1B_efile_FY02.txt\n",
      "Converting H1B_efile_FY02.txt to parquet\n",
      "H1B_efile_FY02.xlsx has same data and datatypes as that of converted H1B_efile_FY02.snappy.parquet\n",
      "Processing file: H1B_Fax_FY2006_External_Web.txt\n",
      "H-1B_Fax_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....H1B_Fax_FY2006_External_Web.txt\n",
      "Converting H1B_Fax_FY2006_External_Web.txt to parquet\n",
      "H1B_Fax_FY2006_External_Web.xlsx has same data and datatypes as that of converted H1B_Fax_FY2006_External_Web.snappy.parquet\n",
      "Processing file: H1B_Fax_FY2005_Download.txt\n",
      "H-1B_Fax_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....H1B_Fax_FY2005_Download.txt\n",
      "Converting H1B_Fax_FY2005_Download.txt to parquet\n",
      "H1B_Fax_FY2005_Download.xlsx has same data and datatypes as that of converted H1B_Fax_FY2005_Download.snappy.parquet\n",
      "Processing file: H1B_fax_FY04.txt\n",
      "H-1B_Fax_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....H1B_fax_FY04.txt\n",
      "Converting H1B_fax_FY04.txt to parquet\n",
      "H1B_fax_FY04.xlsx has same data and datatypes as that of converted H1B_fax_FY04.snappy.parquet\n",
      "Processing file: H1b_external_fax_FY04_Web.txt\n",
      "H-1B_Fax_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....H1b_external_fax_FY04_Web.txt\n",
      "Converting H1b_external_fax_FY04_Web.txt to parquet\n",
      "H1b_external_fax_FY04_Web.xlsx has same data and datatypes as that of converted H1b_external_fax_FY04_Web.snappy.parquet\n",
      "Processing file: H1B_Fax_FY2003_Download.txt\n",
      "H-1B_Fax_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....H1B_Fax_FY2003_Download.txt\n",
      "Converting H1B_Fax_FY2003_Download.txt to parquet\n",
      "H1B_Fax_FY2003_Download.xlsx has same data and datatypes as that of converted H1B_Fax_FY2003_Download.snappy.parquet\n",
      "Processing file: H1B_FAX_FY2002_Download.txt\n",
      "H-1B_Fax_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....H1B_FAX_FY2002_Download.txt\n",
      "Converting H1B_FAX_FY2002_Download.txt to parquet\n",
      "H1B_FAX_FY2002_Download.xlsx has same data and datatypes as that of converted H1B_FAX_FY2002_Download.snappy.parquet\n",
      "Processing file: H1B_Fax_FY2001_Download.txt\n",
      "H-1B_Fax_Record_Layout_FY01-07.xlsx\n",
      "Reading text file to dataframe....H1B_Fax_FY2001_Download.txt\n",
      "Converting H1B_Fax_FY2001_Download.txt to parquet\n",
      "H1B_Fax_FY2001_Download.xlsx has same data and datatypes as that of converted H1B_Fax_FY2001_Download.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Read already downloaded table map\n",
    "table_map = pd.read_csv(DOWNLOAD_DIR + \"/\" + FOLDER_NAME + \"/\" + YEAR_MONTH + \"/\" + FOLDER_NAME + \"_2001to2007_map.csv\")\n",
    "files = table_map['Actual Disclosure File Name'].tolist()\n",
    "print(\"List of files to download: {0}\".format(files))\n",
    "print(\"Corresponding layout files: {0}\".format(table_map['Actual File Structure'].tolist()))\n",
    "\n",
    "# Use the below two lines of code for testing a single file\n",
    "# layout_file_name = table_map[table_map['Actual Disclosure File Name'] == 'PERM_Disclosure_Data_FY2019.xlsx']['Actual File Structure']\n",
    "# convert_file_to_parquet_delimited(\"EFILE_FY2007.txt\", \"H-1B_Efile_Record_Layout_FY01-07.xlsx\", FOLDER_NAME, YEAR_MONTH)\n",
    "\n",
    "for file in files:\n",
    "    print(\"Processing file: {0}\".format(file))\n",
    "    layout_file_name = table_map[table_map['Actual Disclosure File Name'] == file]['Actual File Structure'].values[0]\n",
    "    send_type = table_map[table_map['Actual Disclosure File Name'] == file]['Type'].values[0]\n",
    "    print(layout_file_name)\n",
    "    convert_file_to_parquet_delimited(file, layout_file_name, FOLDER_NAME, YEAR_MONTH, send_type)\n",
    "    time.sleep(5) # Sleep to give rest to the CPU ;) jk, this line is remnant from other function\n",
    "\n",
    "# clean up and remove from memory\n",
    "del table_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
